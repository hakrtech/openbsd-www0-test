<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
	"http://www.w3.org/TR/html4/loose.dtd">
<html>
 <head>
  <meta http-equiv="Content-Type"
	content="text/html; charset=iso-2022-jp">
  <meta name="resource-type"
	content="document">
  <meta name="description"
	CONTENT="How to make an OpenBSD port; audio">
  <meta name="keywords"
	content="openbsd,ports,audio">
  <meta name="distribution"
	content="global">
  <meta name="copyright"
	content="This document copyright 1998-2002 by OpenBSD.">
  <title>Porting audio applications to OpenBSD</title>
  <link rev="made" HREF="mailto:www@openbsd.org">
 </head>
 <body text="#000000" bgcolor="#FFFFFF" link="#23238E">
<a href="index.html"><img alt="[OpenBSD]" height="30" width="141" src="../images/smalltitle.gif" border="0"></a>

  <h1>オーディオアプリケーションの OpenBSD への移植</h1>

<p>
  このドキュメントは、現時点ではサウンド関連のみを取り扱っています。
  シンセサイザや波形の表などの寄付を歓迎します。

</p>
<p>
	オーディオアプリケーションは、まだインターフェイスが標準化されていない
	領域であるため、移植が難しいものとなりがちですが、オペレーティングシステム
	間でのアプローチにあまり変化がないものでもあります。
</p>

  <h2><font color="#e00000"><code>ossaudio</code> の使用</font></h2>

  <code>ossaudio</code> エミュレーションはおそらく最も単純な方法ですが、
  必ずしも動くとは限りませんし、通常はすばらしいアイディアの類でもありません。
  <ul>
	<li>これは <code>ioctl</code> を再定義します。移植するコードがオーディオ
	以外の <code>ioctl</code> を使用している場合、<code>#undef ioctl</code>
	を指定した上で、<code>_ossioctl</code> でそのままの形を使用する必要が
	あります。

	<li>Linux のサウンドのいくつかの機能はエミュレートされません。

	<li>Intel 固有ではない Linux のサウンドを正しくサポートする
	アプリケーションでは、これらの機能を使用する傾向があります。

  </ul>

  <h2><font color="#e00000">既存の NetBSD や FreeBSD のコードの使用</font></h2>
  NetBSD や FreeBSD とオーディオインターフェイスの部分を共有しているので、
  NetBSD の port から始めるのは理に適っています。ただし、いくつかのファイルは
  置き場所が変っていますので注意が必要です。また、<code>sys/audioio.h</code>
  のいくつかのエントリを使用されなくなりました。同様に、多くの ports は間違って
  コーディングされ、たったひとつのタイプのマシンでしか動かないことも多いのです。
  なので、ある種の変更が必要になります。次の部分をよくお読みください。

  <h2><font color="#e00000">OpenBSD のコードの書き方</font></h2>
	  <h3><font color="#0000e0">ハードウェア依存</font></h3>

   <p>
	<strong>使用されているオーディオハードウェアについて何も仮定すべきではありません。
	</strong><br>
	間違ったコードは、<code>a_info.play.precision</code> フィールドが 8 か 16 ビット
	かだけをチェックし、サウンドブラスターの挙動に基づいて、符合なしか符合付きかを
	仮定してしまっています。サンプルの型は明示的にチェックすべきですし、それに従って
	コーディングしなければなりません。以下に単純な例を示します。
   <p>
	<pre>
    AUDIO_INIT_INFO(&amp;a_info);
    a_info.play.encoding = AUDIO_ENCODING_SLINEAR;
    a_info.play.precision = 16;
    a_info.play.sample_rate = 22050;
    error = ioctl(audio, AUDIO_SETINFO, &amp;a_info);
    if (error)
	/* deal with it */
    error = ioctl(audio, AUDIO_GETINFO, &amp;a_info);
    switch(a_info.play.encoding)
	{
    case AUDIO_ENCODING_ULINEAR_LE:
    case AUDIO_ENCODING_ULINEAR_BE:
	if (a_info.play.precision == 8)
	    /* ... */
	else 
	    /* ... */
	break;
    case ...

    default:
	/* don't forget to deal with what you don't know !!! For instance, */
	fprintf(stderr, 
		"Unsupported audio format (%d), ask ports@ about that\n",
		a_info.play.encoding);

	}
    /* now don't forget to check what sampling frequency you actually got */
	</pre>
  
  <p>
  これは、ほとんどの問題を取り扱える、最も小さなコードの断片についてです。

  	<h3><font color="#0000e0">16 ビットフォーマットとエンディアン</font></h3>
	通常の使用において、エンコーディングタイプ (たとえば <code>AUDIO_ENCODING_SLINEAR</code>)
	を問い合わせることで、エンディアンとともにエンコーディングタイプ
	(たとえば <code>AUDIO_ENCODING_SLINEAR_LE</code>) を受け取ります。
	同じエンディアンを使用しなければならないわけではないサウンドカードを
	使用するプラットフォームを考える場合でも、その取り扱に備えるべきです。
	最も簡単なのはおそらく、完全なオーディオバッファを用意して、エンディアンの
	変更を要求された場合には <code>swab(3)</code> を使用する方法でしょう。
	外部のサンプルの取り扱いはおおよそ以下のようになります。
	<ol>
		<li>サンプルフォーマットの解析
		<li>サンプルの取り込み
		<li>ネイティブフォーマットではない場合、エンディアンを変換
		<li>バッファに何を出力したいのかを計算
		<li>サウンドカードがネイティブフォーマットではない場合、エンディアンを変換
		<li>バッファを出力
	</ol>
	たまたま、サウンドカードのネイティブフォーマットであるサウンドのサンプルを
	単純に演奏しようとしている場合には、明かに上記の 3 と 5 のステップを省略
	可能です。

	<h3><font color="#0000e0">音質</font></h3>
	<p>
	たとえば、44100Hz までのモノラルなら可能なのに、ステレオだと 22050Hz 以上に
	できないなどの、おかしな制限をハードウェアが持っていることがあります。このような場合、
	ユーザの好みに応じて状態を変更可能にすべきで、その上で可能な限り最良の性能を出すよう
	最前の努力を尽してください。たとえば、ステレオで出力するためだからとサンプリング
	周波数を 22050Hz に制限したりするのは良いことではありません。もし、ユーザが
	オーディオカードの出力に接続されたステレオサウンドシステムを持っていなかったとしたら
	どうでしょうか ?
	</p>

	<p>
	また、サウンドブラスターのような制限をプログラム中にハードコードしてしまうのも
	愚かな行為です。これらのことには注意すべきではありますが、ステレオで 22050Hz
	以上という壁を乗り越えるために努力し、結果をチェックしてみてください。
	</p>

	<h4>サンプリング周波数</h4>
	カードが返してくるサンプリング周波数は明確にチェックすべきものです。
	5% の誤差というのは既に半音階に達するものですし、ある人々は、
	それ以上に正確な耳を持っていますが、ほとんどの人はあまり気に
	しないでしょう。アプリケーションは、動作中にできるだけ単純に、
	あるいは可能なら、シャノンの再サンプリング方式の回りくどい
	アプリケーションを通して、再サンプリングを可能にすべきです。

	<h4>ダイナミックレンジ</h4>
	<p>
	サンプルは、使用可能なレンジを常時フルに使用するわけではありません。
	まず、低い利得で録音されたサンプルは、ユーザがボリュームを目一杯に上げても、
	マシン上では非常にうるさいほどの音量になることはないでしょう。
	次に、オーディオの絶縁の悪いマシンにおける低い音声出力は、ほとんど
	マシンの騒音を聞いていることになり、期待する音が聞けないことを意味します。
	最後に、16 ビットから 8 ビットへの変換方法が悪いと、ひどく音質の悪い
	4 ビット分しか意味のないオーディオ情報しか残らないことがあります。
	</p>
	<p>
	もし可能なら、最も良い解決策はおそらく、これから演奏しようとしている
	全ストリームをスキャンし、ダイナミックレンジ全体に適合するよう、
	音量を変更することでしょう。もし、その余裕がなくても、今これから
	演奏しようとしているものを少しだけでも取得することができるのでしたら、
	演奏中に音量の増加を調節することもできますが、絶対に
	<em>オーバーフローさせることなく</em>、これから演奏したい音に比べて
	低い周期で音量の調節量を決めなければなりません。
	しかし、このようなことをしても、得ようとしている音質改善の目標より、
	非常に悪いものになってしまうだけでしょう。<br>
	音量の知覚は対数的ですので、算術シフトを使用するだけでも通常は十分でしょう。
	もし、データが符合付きなら、C 言語の <code>&gt;&gt;</code> 演算子は
	符合付きデータに対しては移植可能ではありませんので、
	明示的に除算によるシフトを使用するようコーディングすべきです。
	</p>
	<p>
	もし、すべての方法がうまくいかなければ、少なくともユーザに対して
	音量を調節する手段を提供すべきです。
	</p>

	<h3><font color="#0000e0">オーディオの性能</font></h3>
	<p>
	ローエンドのアプリケーションでは、あまり心配することはありません。
	ローエンドの 68030 上で OpenBSD を使用する人もいることを念頭に置いて、
	もし、サウンドアプリケーションがその上で実行可能なら、そうすべきです。
	</p>

	<p>
	ベンチマークテストの実施を忘れないようにしてください。理論的な最適化は
	理論的なものでしかありません。いくつかの難かしい形については、何が優位で
	何がそうでないのかをチェックするために集めておくべきです。
	</p>

	<p>
	MPEG I - レイヤー 3 のような高性能なオーディオアプリケーションのために、
	いくつかの点を計算に入れておくべきです。
	</p>
	<ul>
	    <li>オーディオインターフェイスは、ハードウェアにとって自然なブロックサイズを
	    用意するものです。そして、出力バッファとしてそれらを複数使用することが
	    基本となります。システムコールである <code>write</code> は、内部での
	    オーディオ処理に比較して高価な処理であるということを覚えておいてください。

	    <li>帯域幅はオーディオを扱う場合に非常に重要な要素となります。
	    オーディオプレイヤーを最適化する上で役に立つ方法は、それを圧縮解除するものと
	    見なすことです。圧縮されたデータとの調和を保つのに十分であり、
	    通常はより良いものでしょう。極く小さな処理を行う非常に小さなループは、
	    通常は良くないアイディアです。一般的に、すべての処理をひとつのループに
	    入れてしまう方がずっと良いものになります。

	    <li>いくつかのフォーマットは、他のものより大きなオーバーヘッドを必要とします。
	    オーディオデバイスが提供するすべてのフォーマットを受け取るために、
	    <code>AUDIO_GETENC</code> <code>ioctl</code> を使用すべきです。
	    特に <code>AUDIO_ENCODINGFLAG_EMULATED</code> フラグには
	    注意してください。もし、あなたのアプリケーションがすべての種類の
	    風変りなフォーマットを出力できるようになっているのでしたら、また、
	    それに対して理に適った最適化を行えるのでしたら、ぜひともネイティブな
	    フォーマットを使用するようにしてください。また、一方で、オーディオデバイスの
	    エミュレーションコードはかなり最適なものであると仮定できますので、
	    それをクイックハックのコードと置き換えようとしないでください。
	</ul>

	最適な結果を得るためにあなたが参考にしなければならないかも知れないモデルは、
	利用可能な特定のオーディオハードウェアについて問い合わせる小さなテストプログラムを
	まずコンパイルすることです。その上で、そのハードウェアを最適に扱うことができるよう、
	あなたのプログラムの構成を続けてください。良いオーディオ性能を欲しい人々が
	ハードウェアを変えた場合に、彼らがあなたの ports を再コンパイルして
	異なるものにしてくれることを、それなりに期待することができるでしょう。
	</p>

	<h3><font color="#0000e0">リアルタイムか同期か</font></h3>
	<p>
	OpenBSD がリアルタイムではないことを考慮してもなお、たとえばゲーム用に
	ほとんどリアルタイムのオーディオアプリケーションをあなたは書きたいと思うかも知れません。
	このような場合、今のゲームと効果音の同期が外れないよう、ブロックサイズを
	より小さくしなければならないでしょう。
	この場合の問題は、恐るべき結果を生じる、オーディオデバイスに供給すべき
	データが間に合わなくなるかも知れないということです。
	</p>
	<p>
	たとえば、オーディオがあるグラフィックスの出力と
	単純に同期することを望んでおり、プログラムの挙動が予測可能である場合は、
	その同期は比較的簡単でしょう。オーディオサンプルを演奏する場合、
	現在演奏中のオーディオデバイスに <code>AUDIO_GETOOFFS</code>
	で問い合わせ、後で同期するグラフィックスへの情報として使用します。
	十分に頻繁に (たとえば 10 秒ごとに) 問い合わせるという条件の下で、
	そして、アプリケーションの実行に十分な馬力がある限り、この方法でも
	この方法でも非常に良好な同期を得ることができるでしょう。
	ただ、現在演奏中のものとオーディオのレポートとの間には若干のタイムラグが
	ありますし、また X Window が何かを表示するための時間もありますので、
	一定のオフセットで波形を微調整しなければならなくなるかも知れません。
	</p>
  <h2><font color="#e00000">コードの寄付</font></h2>
	<p>オーディオアプリケーションの場合、オリジナルのプログラムの
	作者との共同作業が非常に重要です。たとえば、彼のコードが
	サウンドブラスターカードでのみ動くというような場合、これは、
	彼が他の技術に直ちに対処するための、良い機会となるでしょう。
	</p>

	<p>
	<strong>ただしあなたが、あなたのコメントを彼に送らなかったとしたら、
	あなたの作業は役に立たないものになってしまうことでしょう</strong>。</p>

	<p>
	また、あなたが現在取り組んでいるいろいろな問題について、彼は既に注目して
	いるかも知れませんし、彼の現在の開発ツリーにその解決策が織り込まれて
	いるかも知れません。もし、あなたが、少量の行数より多くのパッチを書いているのでしたら、
	ほぼ確実に、彼との共同作業は非常に良いアイディアでしょう。
	</p>

  <hr>
  <a href="porting.html"><img height="24" width="24" src="../back.gif"
   border="0" alt="Porting"></a> 
  <a href="mailto:www@openbsd.org">www@openbsd.org</a>
<br>
<small>
<!-- 
Originally [OpenBSD: audio-port.html,v 1.9 ]
$Translation: audio-port.html,v 1.3 2005/01/20 04:06:14 toshi Exp $
-->
$OpenBSD: audio-port.html,v 1.6 2005/01/20 19:41:28 jufi Exp $
</small>
</body>
</html>
